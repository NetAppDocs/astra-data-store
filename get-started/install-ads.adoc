---
sidebar: sidebar
permalink: get-started/install-ads.html
keywords: astra, astra data store, install, deploy, download
summary: To install Astra Data Store after addressing some environmental prerequisites, you'll download the bundle and install following the steps described.
---

= Install Astra Data Store
:hardbreaks:
:icons: font
:imagesdir: ../media/get-started/

To install Astra Data Store, do the following steps:

* <<Install Astra Data Store>>
* <<Install Astra Trident>>

== Install Astra Data Store

To install Astra Data Store, download the installation bundle from the NetApp Support Site and perform a series a commands to install Astra Data Store Operator and Astra Data Store in your environment. You can use this procedure to install Astra Data Store in internet-connected or air-gapped environments.

.What you'll need
* link:requirements.html[Before you begin installation, prepare your environment for Astra Data Store deployment].
* Root administrative permissions.
* From your OpenShift cluster, ensure all cluster operators are in a healthy state (`available` is `true`):
+
----
oc get clusteroperators
----

* From your OpenShift cluster, ensure all API services are in a healthy state (`available` is `true`):
+
----
oc get apiservices
----

.About this task
The Astra Data Store installation process does the following:

* Installs the Astra components into the `netapp-acc` (or custom named) namespace.
* Creates a default account.
* Establishes a default administrative user email address and default one-time password of `ACC-<UUID_of_installation>` for this instance of Astra Data Store. This user is assigned the Owner role in the system and is needed for first time login to the UI.
* Helps you determine that all Astra Data Store pods are running.
* Installs the Astra UI.

NOTE: Podman commands can be used in place of Docker commands if you are using Red Hat’s Podman repository.

.Steps

Log into NSS and download the Astra Data Store Co-Dev Bundle.
Unpack the bundle then change directory into the resulting folder.
Copy kubectl-astrads binary
Push the images to your local registry.
Install the AstraDSOperator.
Install the AstraDSDeployment.
Install the AstraDSLicense.
Install the AstraDSCluster.

. Log in to the NetApp Support Site and download the Astra Data Store bundle (`astra-data-store-[version].tar.gz`) from the https://mysupport.netapp.com/site/products/all/details/astra-data-store-downloads-tab[NetApp Support Site^].
. Download the zip of Astra Data Store license file (NLF) from https://mysupport.netapp.com/site/products/all/details/astra-data-store/downloads-tab[NetApp Support Site^].
. (Optional) Use the following command to verify the signature of the bundle:
+
----
openssl dgst -sha256 -verify astra-data-store[version].pub -signature <astra-data-store[version].sig astra-control-center[version].tar.gz
----

. Extract the images:
+
----
tar -vxzf astra-data-store-[version].tar.gz
----

. Change to the Astra directory.
+
----
cd astra-data-store-[version]
----

. Define the path where kubectl binary is to be installed. kubectl-astrads is a custom kubectl extension that installs and manages Astra DS clusters.
+
----
which kubectl
/usr/bin/kubectl #Example binary path where kubectl is installed
----

. Copy the kubectl-astrads binary to the standard path where k8s kubectl binaries are installed.
+
----
$ cp -f kubectl-astrads <path from previous command>
----

. Add the files in the Astra Data Store image directory to your local registry.
+
NOTE: See a sample script for the automatic loading of images below.

.. Log in to your Docker registry:
+
----
docker login [Docker_registry_path]
----

.. Load the images into Docker.
.. Tag the images.
.. Push the images to your local registry.

+
----
export REGISTRY=[Docker_registry_path]
for astraImageFile in $(ls images/*.tar)
  # Load to local cache. And store the name of the loaded image trimming the 'Loaded images: '
  do astraImage=$(docker load --input ${astraImageFile} | sed 's/Loaded image(s): //')
  astraImage=$(echo ${astraImage} | sed 's!localhost/!!')
  # Tag with local image repo.
  docker tag ${astraImage} ${REGISTRY}/${astraImage}
  # Push to the local repo.
  docker push ${REGISTRY}/${astraImage}
done
----

. Install the AstraDSOperator:
.. List the AstraDS manifests:
+
----
[<root ID> ~]# ls manifests/
astrads_v1alpha1_astradscluster_external.yaml  astrads_v1alpha1_astradsdeployment_external.yaml  astrads_v1alpha1_astradsoperator_external.yaml
----

.. Edit the Astra Data Store operator custom resource definition (CRD) yaml to refer to your local registry and secret.
+
----
vim astrads_v1alpha1_astradsoperator_external.yaml
----

... Change `[Docker_registry_path]` for the `kube-rbac-proxy` image to the registry path where you pushed the images in a previous step.
... Change `[Docker_registry_path]` for the `ads-operator` image to the registry path where you pushed the images in a previous step.
+
[subs=+quotes]
----
apiVersion: v1
kind: Namespace
metadata:
  labels:
    control-plane: operator
  name: astrads-system
---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
.
.
.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    control-plane: operator
  name: astrads-operator
  namespace: astrads-system
spec:
  replicas: 1
  selector:
    matchLabels:
      control-plane: operator
  template:
    metadata:
      labels:
        control-plane: operator
    spec:
      containers:
      - args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=10
        image: [Docker_registry_path]/kube-rbac-proxy:v0.6.0
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
      - command:
        - /operator
        image: [Docker_registry_path]/ads-operator:dev-6091923
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - liveness -heartbeat 30
          failureThreshold: 3
          initialDelaySeconds: 30
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 15
        name: manager
        resources:
          limits:
            cpu: 100m
            memory: 30Mi
          requests:
            cpu: 100m
            memory: 20Mi
      terminationGracePeriodSeconds: 10
----

.. Apply the updated file to your Astra Data Store cluster:
+
----
kubectl apply -f astrads_v1alpha1_astradsoperator_external.yaml
----

.. Verify that the Astra Data Store operator pod has restarted and is running:
+
----
[<root ID> ~]$ kubectl get pods -n astrads-system
----
+
Response:
+
----
NAME                                READY   STATUS    RESTARTS   AGE
astrads-operator-56d9b69cf4-tkfcb   2/2     Running   0          85s
----

. Edit the Astra Data Store deployment custom resource (CR) file:
.. VIM the yaml file:
+
----
vim astrads_v1alpha1_astradsdeployment_external.yaml
----

.. Change `[Docker_registry_path]` to the registry path where you pushed the images in the previous step.

+
[subs=+quotes]
----
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSDeployment
metadata:
name: astradsdeployment
namespace: astrads-system
spec:
images:
*dmsController: [Docker_registry_path]/ads-dms-controller:dev-6093843*
*firetapInstaller: [Docker_registry_path]/ads-firetap-installer:dev-12.75.0-6091923*
*firegen: [Docker_registry_path]/ads-firetap-firegen:dev-6093843*
*firetapMetrics: [Docker_registry_path]/ads-firetap-metrics:dev-6091923*
*clusterController: [Docker_registry_path]/ads-cluster-controller:dev-6093843*
*support: [Docker_registry_path]/ads-support-controller:1.0*
*licenseController: [Docker_registry_path]/ads-license-controller:dev-6091923*
*callhomeListener: [Docker_registry_path]/ads-callhome-listener:dev-6093843*
*autosupportCronjob: [Docker_registry_path]/ads-autosupport-cronjob:dev-6093843*
*fluentBit: [Docker_registry_path]/fluent-bit:1.6.8*
*nodeInfoController: [Docker_registry_path]/ads-nodeinfo-controller:dev-6093843*
*kubeRbacProxy: [Docker_registry_path]/kube-rbac-proxy:v0.6.0*
version: 0.0.1
----

. Edit and apply the Netapp License File (NLF) that you obtained from the Netapp Support Site (NSS) to your Astra Data Store cluster:

.. Copy and paste the content of the NLF after `netappLicenseFile:`.
.. Enter the name of the cluster that you are going to deploy or have already deployed.
+
[subs=+quotes]
----
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSLicense
metadata:
  name: "e900000005"
  namespace: "astrads-system"
spec:
  *netappLicenseFile: <NLF-contents>*
  *adsClusterName: "<Astra-Data-Store-cluster-name>"*
----

.. Create the license file:
+
----
[<root ID> ~]$ kubectl apply -f <sample-license-yaml>
----
+
Response:
+
----
astradslicense.astrads.netapp.io/e900000005 created
----

.. Verify the changes:
+
----
[<root ID> ~]$ kubectl get astradslicense -A
----
+
Response:
+
----
NAMESPACE        NAME         ADSCLUSTER                      VALID   PRODUCT                       EVALUATION   ENDDATE      VALIDATED
astrads-system   e900000005   astrads-sti-c6220-09-10-11-12   true    Astra Data Store Enterprise   true         2021-12-01   2021-06-23T23:36:11Z
----

. Install the Astra Data Store cluster:
.. VIM the yaml file:
+
----
vim astrads_v1alpha1_astradscluster_external.yaml
----

.. In `metadata`, change the `name` string to the name of your cluster.
.. Update the following required values in `spec`:
... Change the `mvip` string to the IP address of a floating management IP that is routable from any worker node in the cluster.
... In `adsDataNetworks`, list floating IP addresses (`addresses`) that are routable from any host where you intend to mount a NetApp volume.
... In `astraOptions`, add the license number (`serialNumber`) from the NLF.
... In `adsNodeConfig`, enter the per-node CPU core count and memory limits for the FireTap container.
.. (Optional) The following values can be optionally modified otherwise the default value will be used:
... In `spec`, enter a limit to how many nodes can be in the deployment (`adsNodeCount`).
... In `spec`, enter a selector label that filters out nodes for the cluster (`adsNodeSelector`).
...  In `spec`, provide a key that defines which protection domain a node belongs to (`adsProtectionDomainKey`).
... In `adsNetworkInterfaces`, enter the management, cluster, and storage interfaces.
... In `adsNodeConfig`, enter the per-node capacity, name of cache device to be configured for the FireTap container, and drive regex filter to select disks.

+
[subs=+quotes]
----
apiVersion: astrads.netapp.io/v1alpha1
kind: AstraDSCluster
metadata:
  *name: <name of your cluster>*
  namespace: astrads-system
spec:
  *mvip: <management IP address>*
  adsNodeCount: <optional node limit>
  adsNodeSelector: <optional selector label for node filtering>
  adsProtectionDomainKey: <optional key that defines which protection domain a node belongs to>
  adsDataNetworks:
    - *addresses: <CSV list of floating IP addresses>*
      netmask:
      gateway:
  adsNetworkInterfaces:
    managementInterface: <Optional management interface>
    clusterInterface: <Optional cluster interface>
    storageInterface: <Optional storage interface>
  astraOptions:
    *serialNumber: <serial number from license file>*
  adsNodeConfig:
    *cpu: <per-node cpu core count>*
    *memory: <per node memory limit>*
    capacity: <optional limit for per-node raw storage consumption>
    cacheDevice: <optional name of device to be configured as cache device for FireTap container>
    drivesFilter: <optional regex filter to select disks>
  autoSupportConfig:
    historyRetentionCount: 10
    destinationURL: "https://testbed.netapp.com/put/AsupPut"
    periodic:
      - schedule: "0 0 * * 0"
        periodicconfig:
        - component:
            name: controlplane
            event: weekly
          userMessage: Weekly Control Plane AutoSupport bundle
----

. Verify the cluster deployment progress:
+
----
kubectl get astradscluster -n astrads-system
----

Sample return:
+
----
NAME                        STATUS    VERSION                            SERIAL NUMBER   MVIP           AGE

sample-0309d8b   created   sample-9.11.0-6090501   081856669       10.224.8.232   13d
----

. Run the following bash script after cluster creation to reserve node CPU and memory resources to constrain k8s:
+
----
#!/bin/bash
set -eio pipefail
CPU=8
MEM=32


CLUSTER_KIND="AstraDSCluster"
LDIR="/tmp/ADS"
LABEL_PREFIX="astrads.netapp.io"
SSH="ssh"
SCP="scp"
mkdir -p ${LDIR}
if ! CLUSTER_NAME=`kubectl get ${CLUSTER_KIND} -A -o jsonpath={.items[0].metadata.name}` ; then
        CLUSTER_NAME=""
fi
SCRIPT=${LDIR}/sys_res.sh
KUBE_RESERVED='{cpu: 8000m, memory: 32G}'
echo "#!/bin/bash
cat /var/lib/kubelet/config.yaml | python3 -c \"import yaml,sys; y = yaml.load(sys.stdin); y['systemReserved'] = yaml.safe_load(sys.argv[1]); print(yaml.dump(y,default_flow_style=False))\" \"${KUBE_RESERVED}\" > /var/lib/kubelet/config.yaml.new
mv /var/lib/kubelet/config.yaml.new /var/lib/kubelet/config.yaml
echo \"Restarting kubelet\"
systemctl restart kubelet
sleep 10
systemctl status kubelet
grep -A 3 "systemReserved" /var/lib/kubelet/config.yaml
" > ${SCRIPT}
kubectl get nodes  -L ${LABEL_PREFIX}/cluster -o wide
NODES=`kubectl get nodes -L ${LABEL_PREFIX}/cluster | awk /${CLUSTER_NAME}/'{print $1}'`
for NODE in $NODES ; do
        echo "$NODE"
        $SCP ${SCRIPT} root@${NODE}:sys_res.sh
        $SSH root@${NODE} chmod +x sys_res.sh
        $SSH root@${NODE} ./sys_res.sh
done
----

== Install Astra Trident

To install Trident, download the installation bundle from the NetApp Support Site and perform a series a commands to install Trident in your environment. You can use this procedure to install Trident in internet-connected or air-gapped environments.

.What you'll need
* link:requirements.html[Before you begin installation, prepare your environment for Astra Data Store deployment].
* Root administrative permissions.
* If you are installing from an air-gapped environment, download the Trident bundle from the NetApp Support Site.

.Steps
. Create and open a new Trident directory:
+
----
[root@example ~]# mkdir trident
[root@example ~]# cd trident
----

. If you are installing from an internet-connected environment, download the Trident bundle from the NetApp Support Site using a secure, file-transfer tool, such as GNU wget:
+
----
[root@example trident]# wget <URL for Trident bundle>
Resolving ... 10.193.34.109
Connecting to |10.193.34.109|:8081... connected.
HTTP request sent, awaiting response... 200 OK
Length: 87210186 (83M) [application/x-tgz]
Saving to: ‘trident-90cf892ddcc0983dfb875c95d3f55bb602d0202f.tgz’

100%[======================================================================================================================================================================================================================================>] 87,210,186   107MB/s   in 0.8s

2021-07-01 16:31:43 (107 MB/s) - ‘trident-90cf892ddcc0983dfb875c95d3f55bb602d0202f.tgz’ saved [87210186/87210186]
----

. Extract the images from the bundle:
+
Sample command and response:
----
[root@example trident]# gunzip trident-90cf892ddcc0983dfb875c95d3f55bb602d0202f.tgz
trident_docker_image.tgz
trident-operator_docker_image.tgz
trident-installer-21.07.0-test.jenkins-trident-submit-287.tar.gz
trident-operator-21.07.0-test.jenkins-trident-submit-287.tgz
----

. Load the Trident images into your preferred registry. All images should be loaded under one parent directory path; for example,  `nexus.barnacle.company.com:5001/trident`.
+
Sample commands and responses:
----
[root@example trident]# docker load -i trident_docker_image.tgz
d2de0904777e: Loading layer [==================================================>] 51.69 MB/51.69 MB
c110bbf04909: Loading layer [==================================================>]  39.7 MB/39.7 MB
0f7ceb16c114: Loading layer [==================================================>] 1.248 MB/1.248 MB
Loaded image: nexus.barnacle.company.com:5001/trident:21.07.0-test.jenkins-trident-submit-287

[root@example trident]# docker images | grep trident
nexus.barnacle.netapp.com:5001/trident             21.07.0-test.jenkins-trident-submit-287   9ed44525ee10        8 days ago          94.4 MB
----

. Install Trident:





.. Change the `accountName` string to the name you want to associate with the account.
.. Change the `astraAddress` string to the FQDN you want to use in your browser to access Astra. Do not use `http://` or `https://` in the address. Copy this FQDN for use in a <<Log in to the Astra Data Store UI,later step>>.
.. Change the `email` string to the default initial administrator address. Copy this email address for use in a <<Log in to the Astra Data Store UI,later step>>.
.. Change `enrolled` for autoSupport to `false` for sites without internet connectivity or retain `true` for connected sites.
.. (Optional) Add a first name `firstName` and last name `lastName` of the user associated with the account. You can perform this step now or later within the UI.
.. (Optional) Change the `storageClass` value to another Trident storageClass resource if required by your installation.
.. If you are not using a registry that requires authorization, delete the `secret` line.

+
[subs=+quotes]
----
apiVersion: astra.netapp.io/v1
kind: AstraControlCenter
metadata:
  name: astra
spec:
  *accountName: "Example"*
  astraVersion: "ASTRA_VERSION"
  *astraAddress: "astra.example.com"*
  autoSupport:
    *enrolled: true*
  *email: "[admin@example.com]"*
  *firstName: "SRE"*
  *lastName: "Admin"*
  imageRegistry:
    *name: "[Docker_registry_path]"*
    *secret: "astra-registry-cred"*
    *storageClass: "ontap-gold"*
----

. Install the Astra Data Store operator:
+
----
kubectl apply -f astra_control_center_operator_deploy.yaml
----
+
Sample response:
+
----
namespace/netapp-acc-operator created
customresourcedefinition.apiextensions.k8s.io/astracontrolcenters.astra.netapp.io created
role.rbac.authorization.k8s.io/acc-operator-leader-election-role created
clusterrole.rbac.authorization.k8s.io/acc-operator-manager-role created
clusterrole.rbac.authorization.k8s.io/acc-operator-metrics-reader created
clusterrole.rbac.authorization.k8s.io/acc-operator-proxy-role created
rolebinding.rbac.authorization.k8s.io/acc-operator-leader-election-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/acc-operator-manager-rolebinding created
clusterrolebinding.rbac.authorization.k8s.io/acc-operator-proxy-rolebinding created
configmap/acc-operator-manager-config created
service/acc-operator-controller-manager-metrics-service created
deployment.apps/acc-operator-controller-manager created
----

. If you didn't already do so in a previous step, create the `netapp-acc` (or custom) namespace:
+
----
kubectl create ns [netapp-acc or custom]
----
+
Sample response:
+
----
namespace/netapp-acc created
----

. Install Astra Data Store in the `netapp-acc` (or your custom) namespace:
+
----
kubectl apply -f astra_control_center_min.yaml -n [netapp-acc or custom]
----
+
Sample response:
+
----
astracontrolcenter.astra.netapp.io/astra created
----

. Verify that all system components installed successfully.
+
----
kubectl get pods -n [netapp-acc or custom]
----
+
Each pod should have a status of `Running`. It may take several minutes before the system pods are deployed.
+
Sample response:
+
----
NAME                                         READY   STATUS    RESTARTS   AGE
acc-helm-repo-5fdfff786f-gkv6z               1/1     Running   0          4m58s
activity-649f869bf7-jn5gs                    1/1     Running   0          3m14s
asup-79846b5fdc-s9s97                        1/1     Running   0          3m10s
authentication-84c78f5cf4-qhx9t              1/1     Running   0          118s
billing-9b8496787-v8rzv                      1/1     Running   0          2m54s
bucketservice-5fb876d9d5-wkfvz               1/1     Running   0          3m26s
cloud-extension-f9f4f59c6-dz6s6              1/1     Running   0          3m
cloud-insights-service-5676b8c6d4-6q7lv      1/1     Running   0          2m52s
composite-compute-7dcc9c6d6c-lxdr6           1/1     Running   0          2m50s
composite-volume-74dbfd7577-cd42b            1/1     Running   0          3m2s
credentials-75dbf46f9d-5qm2b                 1/1     Running   0          3m32s
entitlement-6cf875cb48-gkvhp                 1/1     Running   0          3m12s
features-74fd97bb46-vss2n                    1/1     Running   0          3m6s
fluent-bit-ds-2g9jb                          1/1     Running   0          113s
fluent-bit-ds-5tg5h                          1/1     Running   0          113s
fluent-bit-ds-qfxb8                          1/1     Running   0          113s
graphql-server-7769f98b86-p4qrv              1/1     Running   0          90s
identity-566c566cd5-ntfj6                    1/1     Running   0          3m16s
influxdb2-0                                  1/1     Running   0          4m43s
krakend-5cb8d56978-44q66                     1/1     Running   0          93s
license-66cbbc6f48-27kgf                     1/1     Running   0          3m4s
login-ui-584f7fd84b-dmdrp                    1/1     Running   0          87s
loki-0                                       1/1     Running   0          4m44s
metrics-ingestion-service-6dcfddf45f-mhnvh   1/1     Running   0          3m8s
monitoring-operator-78d67b4d4-nxs6v          2/2     Running   0          116s
nats-0                                       1/1     Running   0          4m40s
nats-1                                       1/1     Running   0          4m26s
nats-2                                       1/1     Running   0          4m15s
nautilus-9b664bc55-rn9t8                     1/1     Running   0          2m56s
openapi-dc5ddfb7d-6q8vh                      1/1     Running   0          3m20s
polaris-consul-consul-5tjs7                  1/1     Running   0          4m43s
polaris-consul-consul-5wbnx                  1/1     Running   0          4m43s
polaris-consul-consul-bfvl7                  1/1     Running   0          4m43s
polaris-consul-consul-server-0               1/1     Running   0          4m43s
polaris-consul-consul-server-1               1/1     Running   0          4m43s
polaris-consul-consul-server-2               1/1     Running   0          4m43s
polaris-mongodb-0                            2/2     Running   0          4m49s
polaris-mongodb-1                            2/2     Running   0          4m22s
polaris-mongodb-arbiter-0                    1/1     Running   0          4m49s
polaris-ui-6648875998-75d98                  1/1     Running   0          92s
polaris-vault-0                              1/1     Running   0          4m41s
polaris-vault-1                              1/1     Running   0          4m41s
polaris-vault-2                              1/1     Running   0          4m41s
storage-backend-metrics-69546f4fc8-m7lfj     1/1     Running   0          3m22s
storage-provider-5d46f755b-qfv89             1/1     Running   0          3m30s
support-5dc579865c-z4pwq                     1/1     Running   0          3m18s
telegraf-ds-4452f                            1/1     Running   0          113s
telegraf-ds-gnqxl                            1/1     Running   0          113s
telegraf-ds-jhw74                            1/1     Running   0          113s
telegraf-rs-gg6m4                            1/1     Running   0          113s
telemetry-service-6dcc875f98-zft26           1/1     Running   0          3m24s
tenancy-7f7f77f699-q7l6w                     1/1     Running   0          3m28s
traefik-769d846f9b-c9crt                     1/1     Running   0          83s
traefik-769d846f9b-l9n4k                     1/1     Running   0          67s
trident-svc-8649c8bfc5-pdj79                 1/1     Running   0          2m57s
vault-controller-745879f98b-49c5v            1/1     Running   0          4m51s
----

. (Optional) To ensure the installation is completed, you can watch the `acc-operator` logs using the following command.
+
----
kubectl logs deploy/acc-operator-controller-manager -n netapp-acc-operator -c manager -f
----

. When all the pods are running, verify installation success by retrieving the AstraControlCenter instance installed by the ACC Operator.
+
----
kubectl get acc -o yaml -n netapp-acc
----

. Check the `status.deploymentState` field in the response for the `Deployed` value. If deployment was unsuccessful, an error message appears instead.
+
NOTE: You will use the `uuid` in the next step.

+
[subs=+quotes]
----
apiVersion: v1
items:
- apiVersion: astra.netapp.io/v1
  kind: AstraControlCenter
  metadata:
    creationTimestamp: "2021-07-28T21:36:49Z"
    finalizers:
    - astracontrolcenter.netapp.io/finalizer
   generation: 1
    name: astra
    namespace: netapp-acc
    resourceVersion: "27797604"
    selfLink: /apis/astra.netapp.io/v1/namespaces/netapp-acc/astracontrolcenters/astra
    uid: 61cd8b65-047b-431a-ba35-510afcb845f1
  spec:
    accountName: Example
    astraAddress: astra.example.com
    astraResourcesScaler: "Off"
    astraVersion: 21.08.52
    autoSupport:
      enrolled: false
    email: admin@example.com
    firstName: SRE
    lastName: Admin
    imageRegistry:
      name: registry_name/astra
  status:
    certManager: deploy
    *deploymentState: Deployed*
    observedGeneration: 1
    observedVersion: 21.08.52
    postInstall: Complete
    *uuid: c49008a5-4ef1-4c5d-a53e-830daf994116*
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
----

. To get the one-time password you will use when you log in to Astra Data Store, copy the `status.uuid` value from the response in the previous step. The password is `ACC-` followed by the UUID value (`ACC-[UUID]` or, in this example, `ACC-c49008a5-4ef1-4c5d-a53e-830daf994116`).

== Log in to the Astra Data Store UI

After installing ACC, you will change the password for the default administrator and log in to the ACC UI dashboard.

.Steps
. In a browser, enter the FQDN you used in the `astraAddress` in the  `astra_control_center_min.yaml` CR when <<Install Astra Data Store,you installed ACC>>.
. Accept the self-signed certificates when prompted.
+
NOTE: You can create a custom certificate after login.

. At the Astra Data Store login page, enter the value you used for `email` in `astra_control_center_min.yaml` CR when <<Install Astra Data Store,you installed ACC>>, followed by the one-time password (`ACC-[UUID]`).
+
NOTE: If you enter an incorrect password three times, the admin account will be locked for 15 minutes.

. Select *Login*.
. Change the password when prompted.
+
NOTE: If this is your first login and you forget the password and no other administrative user accounts have yet been created, contact NetApp Support for password recovery assistance.

. (Optional) Remove the existing self-signed TLS certificate and replace it with a link:../get-started/add-custom-tls-certificate.html[custom TLS certificate signed by a Certificate Authority (CA)].

== Troubleshoot the installation

If any of the services are in `Error` status, you can inspect the logs. Look for API response codes in the 400 to 500 range. Those indicate the place where a failure happened.

.Steps

. To inspect the Astra Data Store operator logs, enter the following:
+
----
kubectl logs --follow -n netapp-acc-operator $(kubectl get pods -n netapp-acc-operator -o name)  -c manager
----

== What's next

Complete the deployment by performing link:setup_overview.html[setup tasks].
